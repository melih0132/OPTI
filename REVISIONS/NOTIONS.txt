Cours : Programmation Linéaire (PL)

Objectif :
- Trouver la meilleure solution pour une situation où plusieurs conditions doivent être respectées. Par exemple, combien de vélos fabriquer pour maximiser le profit tout en respectant des limites de temps et de ressources.

Étapes pour résoudre un problème de PL :

1. Définir les variables :
   - Choisissez des variables pour représenter ce que vous comptez mesurer. 
     - Exemple : 
       - x = nombre de vélos de montagne fabriqués,
       - y = nombre de vélos de route fabriqués.

2. Écrire la fonction objectif :
   - C'est ce que vous voulez maximiser (comme le profit) ou minimiser (comme le coût).
     - Pour maximiser le profit : Z = profit par vélo de montagne * x + profit par vélo de route * y
     - Pour minimiser le coût : C = coût par vélo de montagne * x + coût par vélo de route * y

3. Écrire les contraintes :
   - Elles représentent les limites ou règles à respecter.
     - Exemple :
       - Temps d'atelier limité à 90 heures : 4x + 3y <= 90
       - Matériaux limités à 50 unités : x + 2y <= 50
       - On ne peut pas fabriquer un nombre négatif de vélos : x >= 0, y >= 0

4. Représenter graphiquement :
   - Tracez les lignes de vos contraintes sur un graphique. La zone où toutes les lignes se superposent est votre "espace réalisable".
   - https://www.geogebra.org/classic?lang=fr

5. Déterminer la solution optimale :
   - Vérifiez les points d'intersection dans l'espace réalisable pour voir lequel optimise votre fonction objectif.

Algorithme A*

Objectif :
- Trouver le chemin le plus court pour aller d'un point A à un point B dans un réseau.

Comment ça fonctionne ?

1. Deux listes :
   - OPEN : Nœuds à explorer.
   - CLOSED : Nœuds déjà examinés.

2. Fonction de coût :
   - f(n) = g(n) + h(n)
     - g(n) : Le coût réel pour atteindre le nœud n.
     - h(n) : Une estimation du coût restant pour atteindre la destination (heuristique).

3. Étapes :
   - Commencez par mettre le point de départ dans OPEN.
   - Choisissez le nœud avec le plus bas f(n) pour l'explorer.
   - Mettez à jour les coûts pour les voisins de ce nœud.
   - Répétez jusqu'à atteindre le point d'arrivée.

4. Vérification de l'heuristique :
   - L'heuristique doit être admissible, c'est-à-dire qu'elle ne doit pas surestimer le coût réel.

Exemple :
- Si h(n) est la distance à vol d'oiseau, c'est admissible car elle est toujours inférieure ou égale au chemin réel.

Algorithme K-Means

Objectif :
- Diviser un ensemble de points en groupes (clusters) où les points dans un cluster sont plus proches les uns des autres.

Comment ça marche ?

1. Initialisation :
   - Choisir K points comme centres initiaux des clusters. Ces points sont souvent choisis aléatoirement parmi les données.

2. Assignation :
   - Chaque point est assigné au centre le plus proche. La distance entre un point et un centre est généralement calculée à l'aide de la distance euclidienne.
   - Distance Euclidienne : La distance euclidienne entre deux points A(x1, y1) et B(x2, y2) est donnée par la formule :
	distance(A, B) = √((x2 - x1)^2 + (y2 - y1)^2)
   - Pour des données avec plus de deux dimensions, la formule est généralisée comme suit :
	distance(A, B) = √((x2_1 - x1_1)^2 + (x2_2 - x1_2)^2 + ... + (x2_n - x1_n)^2)
   où n est le nombre de dimensions.

3. Recalcul :
   - Recalculez les centres des clusters en prenant la moyenne des points de chaque cluster.

4. Convergence :
   - Répétez jusqu'à ce que les centres ne bougent presque plus.

Application pratique :
- Choisissez K, initialisez les centres, assignez les points, recalculez les centres, vérifiez la convergence.

Exemple :
- Pour K = 2, initialisez deux centres, assignez chaque point au centre le plus proche, recalculez les centres jusqu'à stabilisation.

Descente de Gradient

Objectif :
- Ajuster des paramètres pour trouver le meilleur résultat d'une fonction.

Comment ça marche ?

1. Calcul de la dérivée :
   - La dérivée montre la direction où la fonction change le plus.

2. Mise à jour des paramètres :
   - Pour minimiser : theta = theta - alpha * dérivée
   - Pour maximiser : theta = theta + alpha * dérivée
   - alpha est le taux d'apprentissage.

3. Répétition jusqu'à la convergence :
   - Continuez jusqu'à ce que les changements soient très petits.

Exemple :
- Pour maximiser Q(T) = -(T - 50)^2 + 100, on ajuste T en montant le gradient.

Branch and Bound

Objectif :
- Résoudre des problèmes où il faut choisir parmi de nombreuses combinaisons possibles.

Comment ça marche ?

1. Génération de branches :
   - Explorez différentes solutions possibles.

2. Calcul des bornes :
   - Trouvez une estimation du coût minimal pour chaque branche.

3. Élimination des branches :
   - Si une branche a un coût estimé plus élevé que la meilleure solution connue, elle est écartée.

4. Répétition :
   - Continuez jusqu'à trouver la meilleure solution.

Exemple :
- Pour le problème du voyageur de commerce, on explore les chemins et élimine ceux qui dépassent une borne connue.

Résumé des méthodes :

Programmation Linéaire : Optimiser sous contraintes.
Algorithme A* : Trouver le chemin le plus court.
K-Means : Grouper des points.
Descente de Gradient : Optimiser une fonction par ajustements.
Branch and Bound : Éliminer les solutions non optimales pour trouver la meilleure.